{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sheet 11\n",
        "\n",
        "To run in Google Colab (highly recommended for exercise 3) go to: \n",
        "https://colab.research.google.com/drive/1kEEEyD_8uFzl97g7nzeEz5UEBKjpBD48?usp=sharing"
      ],
      "metadata": {
        "id": "CkTUgG53QZb6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2-vWywUOfQe"
      },
      "source": [
        "## 1 Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg-aVczDOfQb"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPyD7MqPOfQg"
      },
      "source": [
        "$ E \\in \\mathbb{R}^{p\\times n} $\n",
        "\n",
        "$ E_{(2k), i} = \\sin\\left(2 i \\cdot \\exp\\left(-\\frac{k \\cdot \\log(10000)}{p}\\right)\\right) $\n",
        "\n",
        "$ E_{(2k+1), i} = \\cos\\left(2 i \\cdot \\exp\\left(-\\frac{k \\cdot \\log(10000)}{p}\\right)\\right) $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNxJdGBNOfQg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmhDtVE4OfQi"
      },
      "source": [
        "## 3 Observing Oversmoothing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Dependencies and get data from GitHub (will take a few minutes)\n",
        "# install dependencies\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install mamba -y\n",
        "!mamba install -c rusty1s -c pytorch -c conda-forge -c lcerrone ctg-benchmark cpuonly torchmetrics=0.8.0 jupyter matplotlib\n",
        "\n",
        "# get data from github\n",
        "!git clone https://github.com/hci-unihd/mlph_sheet11/\n",
        "!mv mlph_sheet11/ctg_data ."
      ],
      "metadata": {
        "cellView": "form",
        "id": "0YCHeMSEOpI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oozsAiPTOfQi"
      },
      "outputs": [],
      "source": [
        "from ctg_benchmark.loaders.torch_loader import get_cross_validation_loaders, get_split_loaders\n",
        "from ctg_benchmark.evaluation.metrics import NodeClassificationMetrics, aggregate_class\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import trange\n",
        "from tqdm.auto import tqdm\n",
        "from torch_geometric.nn.models import GCN\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1o0tuRWOfQj"
      },
      "outputs": [],
      "source": [
        "def validation(validation_loader, model):\n",
        "    # set up evaluation\n",
        "    eval_metrics = NodeClassificationMetrics(num_classes=9)\n",
        "\n",
        "    accuracy_records, accuracy_class_records = [], []\n",
        "    stds = []\n",
        "    model.eval()\n",
        "    # TODO: add calculation of mean feature std\n",
        "    with torch.no_grad():\n",
        "        for val_batch in validation_loader:\n",
        "            val_batch = val_batch.to(device)\n",
        "            pred = model.forward(val_batch.x, val_batch.edge_index)\n",
        "            logits = torch.log_softmax(pred, 1)\n",
        "            pred = logits.max(1)[1]\n",
        "            # results is a dictionary containing a large number of classification metrics\n",
        "            results = eval_metrics.compute_metrics(pred.cpu(), val_batch.y.cpu())\n",
        "            acc = results['accuracy_micro']\n",
        "            # aggregate class average the single class accuracy and ignores the embryo sack class (7)\n",
        "            acc_class, _ = aggregate_class(results['accuracy_class'], index=7)\n",
        "\n",
        "            accuracy_records.append(acc)\n",
        "            accuracy_class_records.append(acc_class)\n",
        "    return accuracy_records, accuracy_class_records\n",
        "\n",
        "\n",
        "def simple_trainer(trainer_loader, num_layers=2):\n",
        "    model = GCN(in_channels=74, hidden_channels=64, num_layers=num_layers, out_channels=9, dropout=0.5)\n",
        "    model = model.to(device)\n",
        "    optim = Adam(params=model.parameters(), lr=1e-2, weight_decay=1e-5)\n",
        "    t_range = trange(25, desc=f'Epoch: {0: 03d}, training loss: {0/len(trainer_loader): .2f}')\n",
        "    # basic training loop\n",
        "    for epoch in t_range:\n",
        "        loss_epoch = 0\n",
        "        for batch in trainer_loader:\n",
        "            optim.zero_grad()\n",
        "            batch = batch.to(device)\n",
        "            pred = model.forward(batch.x, batch.edge_index)\n",
        "            logits = torch.log_softmax(pred, 1)\n",
        "            loss = F.nll_loss(logits, batch.y)\n",
        "            loss.backward()\n",
        "\n",
        "            optim.step()\n",
        "\n",
        "            loss_epoch += loss.item()\n",
        "\n",
        "        t_range.set_description(f'Epoch: {epoch + 1: 03d}, training loss: {loss_epoch/len(trainer_loader): .2f}')\n",
        "        t_range.refresh()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmplPia3OfQl"
      },
      "outputs": [],
      "source": [
        "loaders = get_split_loaders(root='./ctg_data', batch_size=1, shuffle=True, grs=('label_grs_surface',))\n",
        "training_loader, validation_loader = loaders['train'], loaders['val']\n",
        "\n",
        "# example training for GCN with 1 layer\n",
        "model = simple_trainer(training_loader, validation_loader, num_layers=1)\n",
        "accuracy_records, accuracy_class_records = validation(validation_loader, model)\n",
        "\n",
        "# report results\n",
        "print(f'\\nGCN results for {num_layers=}:')\n",
        "print(f'Accuracy {np.mean(accuracy_records):.3f} std: {np.std(accuracy_records):.3f}')\n",
        "print(f'Class Accuracy {np.mean(accuracy_class_records):.3f} std: {np.std(accuracy_class_records):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhgkzSZfOfQm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}